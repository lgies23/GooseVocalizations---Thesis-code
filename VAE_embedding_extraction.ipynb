{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11be52310>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df = pd.read_csv('features_and_spectrograms.csv')\n",
    "calls_df['log_padded_spectrogram'] = calls_df['log_padded_spectrogram'].apply(lambda x: np.array(json.loads(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7300 entries, 0 to 7299\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   track_ID                7300 non-null   object \n",
      " 1   clip_ID                 7300 non-null   object \n",
      " 2   goose_ID                7300 non-null   object \n",
      " 3   call_type               7300 non-null   object \n",
      " 4   waveform                7300 non-null   object \n",
      " 5   sr                      7300 non-null   int64  \n",
      " 6   filepath                7300 non-null   object \n",
      " 7   lfccs                   7300 non-null   object \n",
      " 8   peak                    7300 non-null   float64\n",
      " 9   duration                7300 non-null   float64\n",
      " 10  normalized_log_length   7300 non-null   float64\n",
      " 11  log_target_duration     7300 non-null   float64\n",
      " 12  log_padded_spectrogram  7300 non-null   object \n",
      " 13  log_padded_lfccs        7300 non-null   object \n",
      " 14  f0mean                  6484 non-null   float64\n",
      " 15  f0range                 6484 non-null   float64\n",
      " 16  f0min                   6484 non-null   float64\n",
      " 17  f0max                   6484 non-null   float64\n",
      " 18  f0std_dev               6484 non-null   float64\n",
      " 19  mean_slope              6484 non-null   float64\n",
      " 20  f0_q1                   6484 non-null   float64\n",
      " 21  f0_q2                   6484 non-null   float64\n",
      " 22  f0_q3                   6484 non-null   float64\n",
      " 23  hnr                     7300 non-null   float64\n",
      " 24  centr_s                 7300 non-null   float64\n",
      " 25  skew_s                  7300 non-null   float64\n",
      " 26  kurt_s                  7300 non-null   float64\n",
      " 27  std_s                   7300 non-null   float64\n",
      " 28  centr_t                 7300 non-null   float64\n",
      " 29  skew_t                  7300 non-null   float64\n",
      " 30  kurt_t                  7300 non-null   float64\n",
      " 31  std_t                   7300 non-null   float64\n",
      " 32  avg_f_form1             6484 non-null   float64\n",
      "dtypes: float64(23), int64(1), object(9)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "calls_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6484 entries, 0 to 7299\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   track_ID                6484 non-null   object\n",
      " 1   clip_ID                 6484 non-null   object\n",
      " 2   goose_ID                6484 non-null   object\n",
      " 3   call_type               6484 non-null   object\n",
      " 4   log_padded_spectrogram  6484 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 303.9+ KB\n"
     ]
    }
   ],
   "source": [
    "print(len(calls_df[calls_df.isna().any(axis=1)]))\n",
    "calls_df = calls_df.dropna()\n",
    "calls_df = calls_df[[\"track_ID\", \"clip_ID\", \"goose_ID\", \"call_type\", \"log_padded_spectrogram\"]]\n",
    "calls_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(calls_df[\"call_type\"])\n",
    "calls_df[\"encoded_call_type\"] = le.transform(calls_df[\"call_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 256 # very unbalanced dataset so choosing a bigger batch size - TODO balance\n",
    "epochs = 60\n",
    "retrain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 170)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_df.iloc[0][\"log_padded_spectrogram\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDS(Dataset):\n",
    "    # Custom data loader \n",
    "    def __init__(self, calls_df):\n",
    "        self.df = calls_df\n",
    "                \n",
    "    # of items in dataset\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    \n",
    "    # Get item through index\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram = torch.from_numpy(self.df.iloc[idx][\"log_padded_spectrogram\"]).to(torch.float32).to(device)\n",
    "        spectrogram = spectrogram[np.newaxis, ...]\n",
    "        return spectrogram, self.df.iloc[idx][\"encoded_call_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SoundDS(calls_df)\n",
    "\n",
    "# Random split for train:val - 80:20\n",
    "num_items = len(ds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(ds, [num_train, num_val])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([256, 1, 44, 170])\n",
      "Labels batch shape, type: torch.Size([256])\n",
      "44 170\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dl))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape, type: {train_labels.size()}\")\n",
    "\n",
    "input_size=train_features.size()[1:]\n",
    "print(input_size[1], input_size[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goose_vocalizations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
